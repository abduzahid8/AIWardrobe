{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¨ AIWardrobe - Train Clothing Detection AI (FREE)\n",
                "\n",
                "This notebook trains YOLOv8 on **2M+ clothing images** using Google Colab's free GPU.\n",
                "\n",
                "## Datasets Used:\n",
                "- **DeepFashion2**: 800K images, 13 categories\n",
                "- **iMaterialist**: 1M+ images, fine-grained fashion\n",
                "- **ModaNet**: 55K street fashion images\n",
                "\n",
                "## Training Time:\n",
                "- ~4 hours on Colab T4 GPU (free tier)\n",
                "- ~1 hour on Colab A100 GPU (Colab Pro)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install ultralytics opencv-python-headless albumentations wandb -q\n",
                "!pip install gdown kaggle -q\n",
                "\n",
                "# Check GPU\n",
                "import torch\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "print(f\"CUDA: {torch.version.cuda}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Download Datasets (2M+ Images)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Create directories\n",
                "!mkdir -p datasets/clothing/images/train\n",
                "!mkdir -p datasets/clothing/images/val\n",
                "!mkdir -p datasets/clothing/labels/train\n",
                "!mkdir -p datasets/clothing/labels/val\n",
                "\n",
                "print(\"âœ… Directories created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download iMaterialist from Kaggle (1M+ images)\n",
                "# First, upload your kaggle.json file\n",
                "from google.colab import files\n",
                "\n",
                "print(\"ðŸ“¥ Upload your kaggle.json file:\")\n",
                "print(\"   Get it from: https://www.kaggle.com/settings -> Create New Token\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "!mkdir -p ~/.kaggle\n",
                "!mv kaggle.json ~/.kaggle/\n",
                "!chmod 600 ~/.kaggle/kaggle.json\n",
                "\n",
                "# Download iMaterialist Fashion 2019\n",
                "!kaggle competitions download -c imaterialist-fashion-2019-FGVC6 -p datasets/imaterialist\n",
                "!unzip -q datasets/imaterialist/*.zip -d datasets/imaterialist/\n",
                "\n",
                "print(\"âœ… iMaterialist downloaded (1M+ images)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download ModaNet (55K images) - Direct link\n",
                "!wget -q \"https://github.com/eBay/modanet/archive/refs/heads/master.zip\" -O modanet.zip\n",
                "!unzip -q modanet.zip -d datasets/\n",
                "\n",
                "# Download COCO-style annotations\n",
                "!gdown --id 1B9NJVXP-0a3V0xV-YvVXjDAbcGJq0xqu -O datasets/modanet_annotations.zip\n",
                "!unzip -q datasets/modanet_annotations.zip -d datasets/modanet/\n",
                "\n",
                "print(\"âœ… ModaNet downloaded (55K images)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Convert to YOLO Format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import shutil\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Clothing classes (46 unified categories)\n",
                "CLOTHING_CLASSES = [\n",
                "    \"t-shirt\", \"shirt\", \"polo\", \"sweater\", \"hoodie\",\n",
                "    \"cardigan\", \"tank_top\", \"blouse\", \"crop_top\", \"turtleneck\",\n",
                "    \"jacket\", \"blazer\", \"coat\", \"parka\", \"bomber\",\n",
                "    \"leather_jacket\", \"denim_jacket\", \"windbreaker\",\n",
                "    \"jeans\", \"pants\", \"trousers\", \"chinos\", \"joggers\",\n",
                "    \"shorts\", \"skirt\", \"leggings\",\n",
                "    \"dress\", \"maxi_dress\", \"midi_dress\", \"mini_dress\",\n",
                "    \"sneakers\", \"boots\", \"loafers\", \"heels\", \"sandals\",\n",
                "    \"flats\", \"oxford_shoes\", \"combat_boots\",\n",
                "    \"bag\", \"backpack\", \"handbag\", \"hat\", \"cap\",\n",
                "    \"belt\", \"scarf\", \"sunglasses\"\n",
                "]\n",
                "\n",
                "def coco_to_yolo(coco_json_path, images_dir, output_dir, class_mapping):\n",
                "    \"\"\"Convert COCO format annotations to YOLO format.\"\"\"\n",
                "    with open(coco_json_path, 'r') as f:\n",
                "        coco = json.load(f)\n",
                "    \n",
                "    # Create category mapping\n",
                "    cat_map = {cat['id']: cat['name'] for cat in coco['categories']}\n",
                "    \n",
                "    # Image ID to filename mapping\n",
                "    img_map = {img['id']: (img['file_name'], img['width'], img['height']) \n",
                "               for img in coco['images']}\n",
                "    \n",
                "    # Group annotations by image\n",
                "    from collections import defaultdict\n",
                "    ann_by_img = defaultdict(list)\n",
                "    for ann in coco['annotations']:\n",
                "        ann_by_img[ann['image_id']].append(ann)\n",
                "    \n",
                "    # Convert each image\n",
                "    converted = 0\n",
                "    for img_id, anns in tqdm(ann_by_img.items(), desc=\"Converting\"):\n",
                "        file_name, width, height = img_map[img_id]\n",
                "        \n",
                "        # YOLO label file\n",
                "        label_lines = []\n",
                "        for ann in anns:\n",
                "            cat_name = cat_map[ann['category_id']]\n",
                "            \n",
                "            # Map to our unified classes\n",
                "            if cat_name.lower() in class_mapping:\n",
                "                class_id = class_mapping[cat_name.lower()]\n",
                "            else:\n",
                "                continue  # Skip unknown classes\n",
                "            \n",
                "            # Convert bbox [x, y, w, h] to YOLO format [x_center, y_center, w, h] normalized\n",
                "            bbox = ann['bbox']\n",
                "            x_center = (bbox[0] + bbox[2] / 2) / width\n",
                "            y_center = (bbox[1] + bbox[3] / 2) / height\n",
                "            w_norm = bbox[2] / width\n",
                "            h_norm = bbox[3] / height\n",
                "            \n",
                "            label_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
                "        \n",
                "        if label_lines:\n",
                "            # Save label file\n",
                "            label_path = Path(output_dir) / (Path(file_name).stem + '.txt')\n",
                "            with open(label_path, 'w') as f:\n",
                "                f.write('\\n'.join(label_lines))\n",
                "            converted += 1\n",
                "    \n",
                "    print(f\"âœ… Converted {converted} images to YOLO format\")\n",
                "\n",
                "# Create class mapping\n",
                "class_mapping = {name: idx for idx, name in enumerate(CLOTHING_CLASSES)}\n",
                "print(f\"Classes: {len(CLOTHING_CLASSES)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Create Dataset Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import yaml\n",
                "\n",
                "# YOLO dataset configuration\n",
                "dataset_config = {\n",
                "    'path': '/content/datasets/clothing',\n",
                "    'train': 'images/train',\n",
                "    'val': 'images/val',\n",
                "    'names': {i: name for i, name in enumerate(CLOTHING_CLASSES)}\n",
                "}\n",
                "\n",
                "with open('clothing_dataset.yaml', 'w') as f:\n",
                "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
                "\n",
                "print(\"âœ… Created clothing_dataset.yaml\")\n",
                "!cat clothing_dataset.yaml"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Train YOLOv8 ðŸš€"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "# Load pretrained YOLOv8 medium model\n",
                "model = YOLO('yolov8m.pt')\n",
                "\n",
                "# Train on clothing dataset\n",
                "results = model.train(\n",
                "    data='clothing_dataset.yaml',\n",
                "    epochs=100,           # 100 epochs for good results\n",
                "    imgsz=640,            # Image size\n",
                "    batch=16,             # Batch size (adjust based on GPU memory)\n",
                "    device=0,             # GPU\n",
                "    project='aiwardrobe',\n",
                "    name='clothing_detector',\n",
                "    exist_ok=True,\n",
                "    \n",
                "    # Data augmentation\n",
                "    hsv_h=0.015,\n",
                "    hsv_s=0.7,\n",
                "    hsv_v=0.4,\n",
                "    degrees=10,\n",
                "    translate=0.1,\n",
                "    scale=0.5,\n",
                "    fliplr=0.5,\n",
                "    mosaic=1.0,\n",
                "    \n",
                "    # Training settings\n",
                "    patience=50,\n",
                "    save_period=10,\n",
                "    workers=4,\n",
                "    amp=True,            # Mixed precision\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ðŸŽ‰ TRAINING COMPLETE!\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Validate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate the trained model\n",
                "model = YOLO('aiwardrobe/clothing_detector/weights/best.pt')\n",
                "metrics = model.val()\n",
                "\n",
                "print(f\"\\nmAP50: {metrics.box.map50:.3f}\")\n",
                "print(f\"mAP50-95: {metrics.box.map:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Download Trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "# Package the model\n",
                "!zip -r aiwardrobe_clothing_detector.zip aiwardrobe/clothing_detector/weights/\n",
                "\n",
                "# Download\n",
                "files.download('aiwardrobe_clothing_detector.zip')\n",
                "\n",
                "print(\"\\nâœ… Download your trained model!\")\n",
                "print(\"   Place 'best.pt' in: alicevision-service/weights/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Test on Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import display, Image as IPImage\n",
                "import cv2\n",
                "\n",
                "# Upload test image\n",
                "print(\"Upload a test image:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "for filename in uploaded.keys():\n",
                "    # Run detection\n",
                "    results = model.predict(filename, save=True)\n",
                "    \n",
                "    # Show result\n",
                "    result_path = results[0].save_dir / filename\n",
                "    display(IPImage(filename=str(result_path)))\n",
                "    \n",
                "    # Print detections\n",
                "    for r in results:\n",
                "        for box in r.boxes:\n",
                "            cls = int(box.cls[0])\n",
                "            conf = float(box.conf[0])\n",
                "            name = CLOTHING_CLASSES[cls]\n",
                "            print(f\"  {name}: {conf:.2f}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
"""
ðŸ‘— CatVTON Virtual Try-On Engine
State-of-the-art diffusion-based virtual try-on

Architecture: Concatenation-based VTON
- Lightweight: 899M parameters (vs billions for IDM-VTON)
- Fast: ~11 seconds per generation on A100
- High quality: Excellent structural integrity

Supports:
- API mode (Fashn.ai, Replicate)
- Local mode (requires GPU with 16GB+ VRAM)
"""

import os
import base64
import logging
import time
from typing import Dict, Optional, Union, Any, Tuple
from dataclasses import dataclass, field
from io import BytesIO
import numpy as np

logger = logging.getLogger(__name__)


# ============================================
# ðŸ‘— DATA STRUCTURES
# ============================================

@dataclass
class TryOnResult:
    """Result from virtual try-on"""
    success: bool
    
    # Generated image
    result_image_b64: str = ""
    
    # Intermediate results
    warped_garment_b64: str = ""
    mask_b64: str = ""
    
    # Metadata
    garment_type: str = ""
    body_type: str = ""
    
    # Processing info
    processing_time_ms: float = 0
    method_used: str = "api"
    
    def to_dict(self) -> Dict:
        return {
            "success": self.success,
            "resultImage": self.result_image_b64,
            "warpedGarment": self.warped_garment_b64,
            "mask": self.mask_b64,
            "garmentType": self.garment_type,
            "bodyType": self.body_type,
            "processingTimeMs": self.processing_time_ms,
            "methodUsed": self.method_used
        }


# ============================================
# ðŸš€ CATVTON ENGINE
# ============================================

class CatVTONEngine:
    """
    ðŸ‘— VIRTUAL TRY-ON ENGINE
    
    CatVTON (Concatenation is All You Need):
    - Simplest SOTA architecture
    - Channel-wise concatenation of garment + masked person
    - Single UNet, no complex cross-attention
    - Fastest diffusion-based VTON
    
    Usage Modes:
    1. API (Fashn.ai) - Commercial ready, pay-per-use
    2. API (Replicate) - Using available VTON models
    3. Local - Self-hosted with proper licensing
    """
    
    # Providers
    PROVIDER_FASHN = "fashn"
    PROVIDER_REPLICATE = "replicate"
    PROVIDER_LOCAL = "local"
    
    def __init__(
        self,
        provider: str = "replicate",
        api_key: str = None
    ):
        """
        Initialize CatVTON engine.
        
        Args:
            provider: API provider (fashn, replicate, local)
            api_key: API key for provider
        """
        self.provider = provider
        self.api_key = api_key or self._get_api_key()
        
        # Local model (lazy loaded)
        self._pipeline = None
        self._pose_estimator = None
        
        logger.info(f"CatVTON initialized (provider={provider})")
    
    def _get_api_key(self) -> Optional[str]:
        """Get API key from environment."""
        if self.provider == "fashn":
            return os.environ.get("FASHN_API_KEY")
        elif self.provider == "replicate":
            return os.environ.get("REPLICATE_API_TOKEN")
        return None
    
    # ============================================
    # ðŸŽ¯ CORE TRY-ON METHODS
    # ============================================
    
    def try_on(
        self,
        person_image: str,
        garment_image: str,
        garment_type: str = "upper_body",
        num_inference_steps: int = 30,
        guidance_scale: float = 2.5
    ) -> TryOnResult:
        """
        Perform virtual try-on.
        
        Args:
            person_image: Base64 person image
            garment_image: Base64 garment/flat image
            garment_type: "upper_body", "lower_body", or "full_body"
            num_inference_steps: Diffusion steps (more = higher quality)
            guidance_scale: CFG scale (higher = more faithful to garment)
            
        Returns:
            TryOnResult with generated image
        """
        start_time = time.time()
        
        try:
            if self.provider == "fashn":
                result = self._try_on_fashn(
                    person_image, garment_image, garment_type
                )
            elif self.provider == "replicate":
                result = self._try_on_replicate(
                    person_image, garment_image, garment_type,
                    num_inference_steps, guidance_scale
                )
            else:
                result = self._try_on_local(
                    person_image, garment_image, garment_type,
                    num_inference_steps, guidance_scale
                )
            
            result.processing_time_ms = (time.time() - start_time) * 1000
            result.garment_type = garment_type
            
            return result
            
        except Exception as e:
            logger.error(f"Try-on failed: {e}")
            return TryOnResult(
                success=False,
                processing_time_ms=(time.time() - start_time) * 1000
            )
    
    def _try_on_fashn(
        self,
        person_image: str,
        garment_image: str,
        garment_type: str
    ) -> TryOnResult:
        """Try-on via Fashn.ai API."""
        import requests
        
        # Map garment type
        category_map = {
            "upper_body": "tops",
            "lower_body": "bottoms",
            "full_body": "one-pieces"
        }
        category = category_map.get(garment_type, "tops")
        
        # Prepare images
        person_b64 = self._ensure_base64(person_image)
        garment_b64 = self._ensure_base64(garment_image)
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model_image": f"data:image/jpeg;base64,{person_b64}",
            "garment_image": f"data:image/jpeg;base64,{garment_b64}",
            "category": category
        }
        
        response = requests.post(
            "https://api.fashn.ai/v1/run",
            headers=headers,
            json=payload
        )
        
        result = response.json()
        
        if result.get("status") == "completed":
            # Get result image
            output_url = result.get("output", {}).get("image_url")
            if output_url:
                # Download result
                img_response = requests.get(output_url)
                result_b64 = base64.b64encode(img_response.content).decode()
                
                return TryOnResult(
                    success=True,
                    result_image_b64=result_b64,
                    method_used="fashn_api"
                )
        
        return TryOnResult(success=False, method_used="fashn_api")
    
    def _try_on_replicate(
        self,
        person_image: str,
        garment_image: str,
        garment_type: str,
        num_inference_steps: int,
        guidance_scale: float
    ) -> TryOnResult:
        """Try-on via Replicate API using IDM-VTON or similar."""
        import replicate
        
        # Prepare images with data URI
        person_b64 = self._ensure_base64(person_image)
        garment_b64 = self._ensure_base64(garment_image)
        
        person_uri = f"data:image/jpeg;base64,{person_b64}"
        garment_uri = f"data:image/jpeg;base64,{garment_b64}"
        
        # Use IDM-VTON on Replicate
        try:
            output = replicate.run(
                "cuuupid/idm-vton:c871bb9b046c4fce9e4ceadc009c6be17b8fc09e6bf0a9a1ee1f48e9e2449e9e",
                input={
                    "human_img": person_uri,
                    "garm_img": garment_uri,
                    "garment_des": f"A {garment_type} garment",
                    "category": "upper_body" if "upper" in garment_type else "lower_body",
                    "denoise_steps": num_inference_steps,
                    "seed": 42
                }
            )
            
            # Output is URL
            if output:
                import requests
                img_response = requests.get(output)
                result_b64 = base64.b64encode(img_response.content).decode()
                
                return TryOnResult(
                    success=True,
                    result_image_b64=result_b64,
                    method_used="idm_vton_replicate"
                )
                
        except Exception as e:
            logger.warning(f"IDM-VTON failed, trying alternative: {e}")
        
        # Fallback to OOTDiffusion
        try:
            output = replicate.run(
                "viktorfa/oot_diffusion:9f8fa4956970dde99689af7488157a30aa152e23953526a605df1d77598343d7",
                input={
                    "model_image": person_uri,
                    "garment_image": garment_uri,
                    "steps": num_inference_steps,
                    "guidance_scale": guidance_scale,
                    "garment_type": "upperbody" if "upper" in garment_type else "lowerbody"
                }
            )
            
            if output and len(output) > 0:
                import requests
                img_response = requests.get(output[0])
                result_b64 = base64.b64encode(img_response.content).decode()
                
                return TryOnResult(
                    success=True,
                    result_image_b64=result_b64,
                    method_used="oot_diffusion_replicate"
                )
                
        except Exception as e:
            logger.error(f"VTON fallback failed: {e}")
        
        return TryOnResult(success=False, method_used="replicate")
    
    def _try_on_local(
        self,
        person_image: str,
        garment_image: str,
        garment_type: str,
        num_inference_steps: int,
        guidance_scale: float
    ) -> TryOnResult:
        """Local try-on (requires model download)."""
        logger.warning("Local VTON not implemented - use API mode")
        return TryOnResult(
            success=False,
            method_used="local"
        )
    
    def _ensure_base64(self, image: str) -> str:
        """Ensure image is clean base64."""
        if ',' in image:
            return image.split(',')[1]
        return image
    
    # ============================================
    # ðŸ› ï¸ PREPROCESSING METHODS
    # ============================================
    
    def extract_garment_mask(self, garment_image: str) -> str:
        """
        Extract clean garment mask for try-on.
        Uses SAM 2 for segmentation.
        """
        try:
            from modules.sam2_segmentation import segment_with_sam2
            
            result = segment_with_sam2(
                garment_image,
                prompt="clothing garment"
            )
            
            return result.get("mask_b64", "")
            
        except Exception as e:
            logger.warning(f"Garment mask extraction failed: {e}")
            return ""
    
    def estimate_body_pose(self, person_image: str) -> Dict:
        """
        Estimate body pose for garment warping.
        Returns pose keypoints.
        """
        try:
            # Use MediaPipe or DWPose
            import cv2
            import mediapipe as mp
            
            # Decode image
            img_bytes = base64.b64decode(self._ensure_base64(person_image))
            nparr = np.frombuffer(img_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            # Run pose estimation
            mp_pose = mp.solutions.pose
            with mp_pose.Pose(
                static_image_mode=True,
                model_complexity=2
            ) as pose:
                results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            if results.pose_landmarks:
                keypoints = []
                for lm in results.pose_landmarks.landmark:
                    keypoints.append({
                        "x": lm.x,
                        "y": lm.y,
                        "z": lm.z,
                        "visibility": lm.visibility
                    })
                return {"success": True, "keypoints": keypoints}
            
            return {"success": False, "keypoints": []}
            
        except Exception as e:
            logger.warning(f"Pose estimation failed: {e}")
            return {"success": False, "keypoints": []}


# ============================================
# ðŸ”§ UTILITY FUNCTIONS
# ============================================

def try_on_garment(
    person_image_b64: str,
    garment_image_b64: str,
    garment_type: str = "upper_body"
) -> Dict:
    """
    Utility function for virtual try-on.
    
    Args:
        person_image_b64: Base64 person image
        garment_image_b64: Base64 garment image
        garment_type: "upper_body", "lower_body", or "full_body"
        
    Returns:
        Try-on result dict
    """
    engine = get_vton_engine()
    result = engine.try_on(person_image_b64, garment_image_b64, garment_type)
    return result.to_dict()


# Singleton instance
_vton_engine = None

def get_vton_engine(provider: str = "replicate") -> CatVTONEngine:
    """Get singleton VTON engine."""
    global _vton_engine
    if _vton_engine is None:
        _vton_engine = CatVTONEngine(provider=provider)
    return _vton_engine
